{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb0392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, f1_score, roc_auc_score, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "# Custom 3D Swin Transformer Block with 6 Layer Normalizations\n",
    "class SwinTransformerBlock3D(nn.Module):\n",
    "    def __init__(self, dim, num_heads, window_size, mlp_ratio=4.0, dropout=0.5):\n",
    "        super(SwinTransformerBlock3D, self).__init__()\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # Define 6 Layer Normalization layers\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.norm3 = nn.LayerNorm(dim)\n",
    "        self.norm4 = nn.LayerNorm(dim)\n",
    "        self.norm5 = nn.LayerNorm(dim)\n",
    "        self.norm6 = nn.LayerNorm(dim)\n",
    "\n",
    "        # Multi-head self-attention\n",
    "        self.attn = nn.MultiheadAttention(dim, num_heads)\n",
    "\n",
    "        # MLP (feed-forward) with dropout\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, int(mlp_ratio * dim)),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),  # Dropout after GELU\n",
    "            nn.Linear(int(mlp_ratio * dim), dim),\n",
    "            nn.Dropout(dropout)  # Dropout after second Linear layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, D, H, W, C = x.shape\n",
    "        x = x.view(B, D * H * W, C)  # Flatten spatial dimensions for attention\n",
    "\n",
    "        # Layer Normalization and Self-Attention with Residual Connection\n",
    "        x = x + self.attn(self.norm1(x), self.norm2(x), self.norm3(x))[0]\n",
    "\n",
    "        # Further normalization before the MLP block\n",
    "        x = self.norm4(x)\n",
    "\n",
    "        # MLP block with residual connection\n",
    "        x = x + self.mlp(self.norm5(x))\n",
    "\n",
    "        # Final normalization before output\n",
    "        x = self.norm6(x)\n",
    "\n",
    "        return x.view(B, D, H, W, C)\n",
    "\n",
    "\n",
    "class SwinTransformer3D(nn.Module):\n",
    "    def __init__(self, img_size=(256, 256, 32), patch_size=(8, 8, 8), in_chans=1, \n",
    "                 num_classes=2, embed_dim=96, depths=[2, 2, 6, 2], num_heads=[3, 6, 12, 24], \n",
    "                 mlp_ratio=4.0, dropout=0.5):\n",
    "        super(SwinTransformer3D, self).__init__()\n",
    "\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Embedding layer (linear projection of patches)\n",
    "        self.patch_embed = nn.Conv3d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "        # Transformer layers with downsampling stages\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.downsamples = nn.ModuleList()\n",
    "\n",
    "        # Initialize input_size after patch embedding\n",
    "        input_size = [dim // p for dim, p in zip(img_size, patch_size)]  # e.g., [32, 32, 4]\n",
    "\n",
    "        for i_layer in range(self.num_layers):\n",
    "            # Swin Transformer blocks for this stage\n",
    "            stage = nn.Sequential(\n",
    "                *[SwinTransformerBlock3D(dim=self.embed_dim, num_heads=num_heads[i_layer], \n",
    "                                         window_size=2, mlp_ratio=mlp_ratio, dropout=dropout) \n",
    "                  for _ in range(depths[i_layer])]\n",
    "            )\n",
    "            self.layers.append(stage)\n",
    "\n",
    "            if i_layer < self.num_layers - 1:\n",
    "                # Determine kernel_size and stride for downsampling\n",
    "                kernel_size, stride = self.get_safe_kernel_and_stride(input_size)\n",
    "\n",
    "                downsample = nn.Conv3d(\n",
    "                    self.embed_dim, self.embed_dim * 2, \n",
    "                    kernel_size=kernel_size, stride=stride\n",
    "                )\n",
    "                self.downsamples.append(downsample)\n",
    "                self.embed_dim *= 2\n",
    "\n",
    "                # Update input_size for next layer\n",
    "                input_size = [\n",
    "                    max(1, (size - (k - 1) - 1) // s + 1)\n",
    "                    for size, k, s in zip(input_size, kernel_size, stride)\n",
    "                ]\n",
    "\n",
    "        # Final bottleneck layer\n",
    "        self.bottleneck = nn.Conv3d(self.embed_dim, self.embed_dim, kernel_size=1)\n",
    "\n",
    "        # Final classifier with dropout\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.embed_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def get_safe_kernel_and_stride(self, input_size):\n",
    "        \"\"\"Ensure the kernel size and stride do not exceed the input size after downsampling.\"\"\"\n",
    "        kernel_size = []\n",
    "        stride = []\n",
    "        for size in input_size:\n",
    "            if size >= 2:\n",
    "                kernel_size.append(2)\n",
    "                stride.append(2)\n",
    "            else:\n",
    "                kernel_size.append(1)\n",
    "                stride.append(1)\n",
    "        return tuple(kernel_size), tuple(stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Patch embedding\n",
    "        x = self.patch_embed(x)  # (B, C, D', H', W')\n",
    "\n",
    "        # Reshape to (B, D', H', W', C)\n",
    "        B, C, D, H, W = x.shape\n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "\n",
    "        # Transformer layers with downsampling\n",
    "        for i_layer, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if i_layer < self.num_layers - 1:\n",
    "                x = x.permute(0, 4, 1, 2, 3)  # Move channels back to second dimension\n",
    "                x = self.downsamples[i_layer](x)  # Apply downsampling\n",
    "                x = x.permute(0, 2, 3, 4, 1)  # Move channels back to last dimension\n",
    "\n",
    "        # Bottleneck layer\n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # Global average pooling\n",
    "        x = x.mean(dim=[2, 3, 4])\n",
    "\n",
    "        # Classification\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Dataset for 3D images\n",
    "class CustomDataset3D(Dataset):\n",
    "    def __init__(self, root_dir, class_labels, target_shape=(256, 256, 32)):\n",
    "        self.root_dir = root_dir\n",
    "        self.class_labels = class_labels\n",
    "        self.target_shape = target_shape\n",
    "        self.samples = self._load_samples()\n",
    "\n",
    "    def _load_samples(self):\n",
    "        samples = []\n",
    "        for class_name, label in self.class_labels.items():\n",
    "            class_path = os.path.join(self.root_dir, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for file_name in os.listdir(class_path):\n",
    "                    if file_name.endswith('.nii') or file_name.endswith('.nii.gz'):\n",
    "                        img_path = os.path.join(class_path, file_name)\n",
    "                        samples.append((img_path, label))\n",
    "        return samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        img = nib.load(img_path).get_fdata()\n",
    "        img = self._pad_or_crop(img)\n",
    "        img = self._normalize(img)\n",
    "        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return img, label\n",
    "\n",
    "    def _pad_or_crop(self, img):\n",
    "        target_shape = self.target_shape\n",
    "        current_shape = img.shape\n",
    "        slices = []\n",
    "        pad_widths = []\n",
    "\n",
    "        for curr_dim, target_dim in zip(current_shape, target_shape):\n",
    "            if curr_dim > target_dim:\n",
    "                start = (curr_dim - target_dim) // 2\n",
    "                end = start + target_dim\n",
    "                slices.append(slice(start, end))\n",
    "                pad_widths.append((0, 0))\n",
    "            elif curr_dim < target_dim:\n",
    "                pad_size = target_dim - curr_dim\n",
    "                pad_left = pad_size // 2\n",
    "                pad_right = pad_size - pad_left\n",
    "                slices.append(slice(0, curr_dim))\n",
    "                pad_widths.append((pad_left, pad_right))\n",
    "            else:\n",
    "                slices.append(slice(0, curr_dim))\n",
    "                pad_widths.append((0, 0))\n",
    "\n",
    "        img = img[slices[0], slices[1], slices[2]]\n",
    "        img = np.pad(img, pad_widths, mode='constant', constant_values=0)\n",
    "        return img\n",
    "\n",
    "    def _normalize(self, img):\n",
    "        img = img - np.min(img)\n",
    "        if np.max(img) != 0:\n",
    "            img = img / np.max(img)\n",
    "        return img\n",
    "\n",
    "# Function to split dataset\n",
    "def split_dataset(dataset, test_size=0.2):\n",
    "    indices = list(range(len(dataset)))\n",
    "    labels = [dataset.samples[i][1] for i in indices]\n",
    "    train_indices, test_indices = train_test_split(indices, test_size=test_size, stratify=labels, random_state=24)\n",
    "    return train_indices, test_indices\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train_model(train_loader, model, criterion, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()  # Move scheduler step outside the batch loop\n",
    "    return running_loss / len(train_loader)\n",
    "\n",
    "def evaluate_model(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    true_labels, pred_labels, pred_probs = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = nn.functional.softmax(outputs, dim=1)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            pred_labels.extend(preds.cpu().numpy())\n",
    "            pred_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(true_labels, pred_labels)\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    f1 = f1_score(true_labels, pred_labels)\n",
    "    try:\n",
    "        auc = roc_auc_score(true_labels, pred_probs)\n",
    "        auc_pr = average_precision_score(true_labels, pred_probs)\n",
    "    except ValueError:\n",
    "        auc = np.nan\n",
    "        auc_pr = np.nan\n",
    "\n",
    "    return acc, cm, f1, auc, auc_pr\n",
    "\n",
    "def cross_validate(dataset, model_class, criterion, optimizer_class, scheduler_class, device, num_epochs=50, k_folds=5):\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=24)\n",
    "    fold_results = []\n",
    "\n",
    "    # Extract labels from the dataset\n",
    "    labels = [dataset[i][1].item() for i in range(len(dataset))]\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(range(len(labels)), labels)):\n",
    "        print(f\"\\nFold {fold+1}/{k_folds}\")\n",
    "\n",
    "        # Create subsets for the current fold\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        train_loader_fold = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        val_loader_fold = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        # Initialize model, optimizer, and scheduler\n",
    "        model = model_class().to(device)\n",
    "        optimizer = optimizer_class(model.parameters())\n",
    "        scheduler = scheduler_class(optimizer)\n",
    "\n",
    "        # Train and evaluate the model for this fold\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = train_model(train_loader_fold, model, criterion, optimizer, scheduler, device)\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')\n",
    "\n",
    "        # Evaluate on the validation set\n",
    "        val_acc, _, val_f1, val_auc, val_auc_pr = evaluate_model(val_loader_fold, model, criterion, device)\n",
    "        print(f'Validation Accuracy: {val_acc:.4f}, F1 Score: {val_f1:.4f}, AUC: {val_auc:.4f}, AUC-PR: {val_auc_pr:.4f}')\n",
    "\n",
    "        fold_results.append((val_acc, val_f1, val_auc, val_auc_pr))\n",
    "\n",
    "    # Calculate and return average metrics across all folds\n",
    "    avg_acc = np.mean([r[0] for r in fold_results])\n",
    "    avg_f1 = np.mean([r[1] for r in fold_results])\n",
    "    avg_auc = np.mean([r[2] for r in fold_results])\n",
    "    avg_auc_pr = np.mean([r[3] for r in fold_results])\n",
    "\n",
    "    return avg_acc, avg_f1, avg_auc, avg_auc_pr\n",
    "\n",
    "# Function to save results to a text file\n",
    "def save_results_to_file(file_path, cv_acc, test_acc, test_auc, test_auc_pr):\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(f\"Cross-validation Accuracy: {cv_acc:.4f}\\n\")\n",
    "        f.write(f\"Test Accuracy: {test_acc:.4f}\\n\")\n",
    "        f.write(f\"Test AUC: {test_auc:.4f}\\n\")\n",
    "        f.write(f\"Test AUC-PR: {test_auc_pr:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f02643d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0587fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "Sequential                                              --\n",
       "├─SwinTransformerBlock3D: 1-1                           --\n",
       "│    └─LayerNorm: 2-1                                   192\n",
       "│    └─LayerNorm: 2-2                                   192\n",
       "│    └─LayerNorm: 2-3                                   192\n",
       "│    └─LayerNorm: 2-4                                   192\n",
       "│    └─LayerNorm: 2-5                                   192\n",
       "│    └─LayerNorm: 2-6                                   192\n",
       "│    └─MultiheadAttention: 2-7                          27,936\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-1        9,312\n",
       "│    └─Sequential: 2-8                                  --\n",
       "│    │    └─Linear: 3-2                                 37,248\n",
       "│    │    └─GELU: 3-3                                   --\n",
       "│    │    └─Dropout: 3-4                                --\n",
       "│    │    └─Linear: 3-5                                 36,960\n",
       "│    │    └─Dropout: 3-6                                --\n",
       "├─SwinTransformerBlock3D: 1-2                           --\n",
       "│    └─LayerNorm: 2-9                                   192\n",
       "│    └─LayerNorm: 2-10                                  192\n",
       "│    └─LayerNorm: 2-11                                  192\n",
       "│    └─LayerNorm: 2-12                                  192\n",
       "│    └─LayerNorm: 2-13                                  192\n",
       "│    └─LayerNorm: 2-14                                  192\n",
       "│    └─MultiheadAttention: 2-15                         27,936\n",
       "│    │    └─NonDynamicallyQuantizableLinear: 3-7        9,312\n",
       "│    └─Sequential: 2-16                                 --\n",
       "│    │    └─Linear: 3-8                                 37,248\n",
       "│    │    └─GELU: 3-9                                   --\n",
       "│    │    └─Dropout: 3-10                               --\n",
       "│    │    └─Linear: 3-11                                36,960\n",
       "│    │    └─Dropout: 3-12                               --\n",
       "================================================================================\n",
       "Total params: 225,216\n",
       "Trainable params: 225,216\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(xmerModel.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fee2db6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "xmerModel = SwinTransformer3D(img_size=(240, 240, 155), patch_size=(8,8,5), in_chans=5, num_classes=2)\n",
    "# summary(xmerModel, input_size=(1, 5, 240, 240, 155))\n",
    "# summary(xmerModel.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca3ac538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "VisionMamba3D                                 [1, 2]                    --\n",
       "├─PatchEmbedding3D: 1-1                       [1, 96, 31, 30, 30]       --\n",
       "│    └─Conv3d: 2-1                            [1, 96, 31, 30, 30]       153,696\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-2                        [1, 27900, 96]            --\n",
       "│    │    └─TransformerBlockWithSSM: 3-1      [1, 27900, 96]            --\n",
       "│    │    │    └─MambaLayer: 4-1              [1, 27900, 96]            --\n",
       "│    │    │    └─LayerNorm: 4-2               [1, 27900, 96]            192\n",
       "│    │    │    └─Sequential: 4-3              [1, 27900, 96]            --\n",
       "│    │    │    │    └─Linear: 5-1             [1, 27900, 384]           37,248\n",
       "│    │    │    │    └─GELU: 5-2               [1, 27900, 384]           --\n",
       "│    │    │    │    └─Dropout: 5-3            [1, 27900, 384]           --\n",
       "│    │    │    │    └─Linear: 5-4             [1, 27900, 96]            36,960\n",
       "│    │    │    │    └─Dropout: 5-5            [1, 27900, 96]            --\n",
       "│    │    └─TransformerBlockWithSSM: 3-2      [1, 27900, 96]            --\n",
       "│    │    │    └─MambaLayer: 4-4              [1, 27900, 96]            --\n",
       "│    │    │    └─LayerNorm: 4-5               [1, 27900, 96]            192\n",
       "│    │    │    └─Sequential: 4-6              [1, 27900, 96]            --\n",
       "│    │    │    │    └─Linear: 5-6             [1, 27900, 384]           37,248\n",
       "│    │    │    │    └─GELU: 5-7               [1, 27900, 384]           --\n",
       "│    │    │    │    └─Dropout: 5-8            [1, 27900, 384]           --\n",
       "│    │    │    │    └─Linear: 5-9             [1, 27900, 96]            36,960\n",
       "│    │    │    │    └─Dropout: 5-10           [1, 27900, 96]            --\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Conv3d: 2-3                            [1, 192, 15, 15, 15]      147,648\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-4                        [1, 3375, 192]            --\n",
       "│    │    └─TransformerBlockWithSSM: 3-3      [1, 3375, 192]            --\n",
       "│    │    │    └─MambaLayer: 4-7              [1, 3375, 192]            --\n",
       "│    │    │    └─LayerNorm: 4-8               [1, 3375, 192]            384\n",
       "│    │    │    └─Sequential: 4-9              [1, 3375, 192]            --\n",
       "│    │    │    │    └─Linear: 5-11            [1, 3375, 768]            148,224\n",
       "│    │    │    │    └─GELU: 5-12              [1, 3375, 768]            --\n",
       "│    │    │    │    └─Dropout: 5-13           [1, 3375, 768]            --\n",
       "│    │    │    │    └─Linear: 5-14            [1, 3375, 192]            147,648\n",
       "│    │    │    │    └─Dropout: 5-15           [1, 3375, 192]            --\n",
       "│    │    └─TransformerBlockWithSSM: 3-4      [1, 3375, 192]            --\n",
       "│    │    │    └─MambaLayer: 4-10             [1, 3375, 192]            --\n",
       "│    │    │    └─LayerNorm: 4-11              [1, 3375, 192]            384\n",
       "│    │    │    └─Sequential: 4-12             [1, 3375, 192]            --\n",
       "│    │    │    │    └─Linear: 5-16            [1, 3375, 768]            148,224\n",
       "│    │    │    │    └─GELU: 5-17              [1, 3375, 768]            --\n",
       "│    │    │    │    └─Dropout: 5-18           [1, 3375, 768]            --\n",
       "│    │    │    │    └─Linear: 5-19            [1, 3375, 192]            147,648\n",
       "│    │    │    │    └─Dropout: 5-20           [1, 3375, 192]            --\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Conv3d: 2-5                            [1, 384, 7, 7, 7]         590,208\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-6                        [1, 343, 384]             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-5      [1, 343, 384]             --\n",
       "│    │    │    └─MambaLayer: 4-13             [1, 343, 384]             --\n",
       "│    │    │    └─LayerNorm: 4-14              [1, 343, 384]             768\n",
       "│    │    │    └─Sequential: 4-15             [1, 343, 384]             --\n",
       "│    │    │    │    └─Linear: 5-21            [1, 343, 1536]            591,360\n",
       "│    │    │    │    └─GELU: 5-22              [1, 343, 1536]            --\n",
       "│    │    │    │    └─Dropout: 5-23           [1, 343, 1536]            --\n",
       "│    │    │    │    └─Linear: 5-24            [1, 343, 384]             590,208\n",
       "│    │    │    │    └─Dropout: 5-25           [1, 343, 384]             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-6      [1, 343, 384]             --\n",
       "│    │    │    └─MambaLayer: 4-16             [1, 343, 384]             --\n",
       "│    │    │    └─LayerNorm: 4-17              [1, 343, 384]             768\n",
       "│    │    │    └─Sequential: 4-18             [1, 343, 384]             --\n",
       "│    │    │    │    └─Linear: 5-26            [1, 343, 1536]            591,360\n",
       "│    │    │    │    └─GELU: 5-27              [1, 343, 1536]            --\n",
       "│    │    │    │    └─Dropout: 5-28           [1, 343, 1536]            --\n",
       "│    │    │    │    └─Linear: 5-29            [1, 343, 384]             590,208\n",
       "│    │    │    │    └─Dropout: 5-30           [1, 343, 384]             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-7      [1, 343, 384]             --\n",
       "│    │    │    └─MambaLayer: 4-19             [1, 343, 384]             --\n",
       "│    │    │    └─LayerNorm: 4-20              [1, 343, 384]             768\n",
       "│    │    │    └─Sequential: 4-21             [1, 343, 384]             --\n",
       "│    │    │    │    └─Linear: 5-31            [1, 343, 1536]            591,360\n",
       "│    │    │    │    └─GELU: 5-32              [1, 343, 1536]            --\n",
       "│    │    │    │    └─Dropout: 5-33           [1, 343, 1536]            --\n",
       "│    │    │    │    └─Linear: 5-34            [1, 343, 384]             590,208\n",
       "│    │    │    │    └─Dropout: 5-35           [1, 343, 384]             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-8      [1, 343, 384]             --\n",
       "│    │    │    └─MambaLayer: 4-22             [1, 343, 384]             --\n",
       "│    │    │    └─LayerNorm: 4-23              [1, 343, 384]             768\n",
       "│    │    │    └─Sequential: 4-24             [1, 343, 384]             --\n",
       "│    │    │    │    └─Linear: 5-36            [1, 343, 1536]            591,360\n",
       "│    │    │    │    └─GELU: 5-37              [1, 343, 1536]            --\n",
       "│    │    │    │    └─Dropout: 5-38           [1, 343, 1536]            --\n",
       "│    │    │    │    └─Linear: 5-39            [1, 343, 384]             590,208\n",
       "│    │    │    │    └─Dropout: 5-40           [1, 343, 384]             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-9      [1, 343, 384]             --\n",
       "│    │    │    └─MambaLayer: 4-25             [1, 343, 384]             --\n",
       "│    │    │    └─LayerNorm: 4-26              [1, 343, 384]             768\n",
       "│    │    │    └─Sequential: 4-27             [1, 343, 384]             --\n",
       "│    │    │    │    └─Linear: 5-41            [1, 343, 1536]            591,360\n",
       "│    │    │    │    └─GELU: 5-42              [1, 343, 1536]            --\n",
       "│    │    │    │    └─Dropout: 5-43           [1, 343, 1536]            --\n",
       "│    │    │    │    └─Linear: 5-44            [1, 343, 384]             590,208\n",
       "│    │    │    │    └─Dropout: 5-45           [1, 343, 384]             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-10     [1, 343, 384]             --\n",
       "│    │    │    └─MambaLayer: 4-28             [1, 343, 384]             --\n",
       "│    │    │    └─LayerNorm: 4-29              [1, 343, 384]             768\n",
       "│    │    │    └─Sequential: 4-30             [1, 343, 384]             --\n",
       "│    │    │    │    └─Linear: 5-46            [1, 343, 1536]            591,360\n",
       "│    │    │    │    └─GELU: 5-47              [1, 343, 1536]            --\n",
       "│    │    │    │    └─Dropout: 5-48           [1, 343, 1536]            --\n",
       "│    │    │    │    └─Linear: 5-49            [1, 343, 384]             590,208\n",
       "│    │    │    │    └─Dropout: 5-50           [1, 343, 384]             --\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Conv3d: 2-7                            [1, 768, 3, 3, 3]         2,360,064\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-8                        [1, 27, 768]              --\n",
       "│    │    └─TransformerBlockWithSSM: 3-11     [1, 27, 768]              --\n",
       "│    │    │    └─MambaLayer: 4-31             [1, 27, 768]              --\n",
       "│    │    │    └─LayerNorm: 4-32              [1, 27, 768]              1,536\n",
       "│    │    │    └─Sequential: 4-33             [1, 27, 768]              --\n",
       "│    │    │    │    └─Linear: 5-51            [1, 27, 3072]             2,362,368\n",
       "│    │    │    │    └─GELU: 5-52              [1, 27, 3072]             --\n",
       "│    │    │    │    └─Dropout: 5-53           [1, 27, 3072]             --\n",
       "│    │    │    │    └─Linear: 5-54            [1, 27, 768]              2,360,064\n",
       "│    │    │    │    └─Dropout: 5-55           [1, 27, 768]              --\n",
       "│    │    └─TransformerBlockWithSSM: 3-12     [1, 27, 768]              --\n",
       "│    │    │    └─MambaLayer: 4-34             [1, 27, 768]              --\n",
       "│    │    │    └─LayerNorm: 4-35              [1, 27, 768]              1,536\n",
       "│    │    │    └─Sequential: 4-36             [1, 27, 768]              --\n",
       "│    │    │    │    └─Linear: 5-56            [1, 27, 3072]             2,362,368\n",
       "│    │    │    │    └─GELU: 5-57              [1, 27, 3072]             --\n",
       "│    │    │    │    └─Dropout: 5-58           [1, 27, 3072]             --\n",
       "│    │    │    │    └─Linear: 5-59            [1, 27, 768]              2,360,064\n",
       "│    │    │    │    └─Dropout: 5-60           [1, 27, 768]              --\n",
       "├─Conv3d: 1-9                                 [1, 768, 3, 3, 3]         590,592\n",
       "├─Sequential: 1-10                            [1, 2]                    --\n",
       "│    └─LayerNorm: 2-9                         [1, 768]                  1,536\n",
       "│    └─Linear: 2-10                           [1, 512]                  393,728\n",
       "│    └─ReLU: 2-11                             [1, 512]                  --\n",
       "│    └─Linear: 2-12                           [1, 2]                    1,026\n",
       "===============================================================================================\n",
       "Total params: 21,521,762\n",
       "Trainable params: 21,521,762\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.09\n",
       "===============================================================================================\n",
       "Input size (MB): 178.56\n",
       "Forward/backward pass size (MB): 387.27\n",
       "Params size (MB): 86.09\n",
       "Estimated Total Size (MB): 651.91\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from model.VisionMamba3D import VisionMamba3D\n",
    "\n",
    "mambamodel = VisionMamba3D(\n",
    "    img_size=(155, 240, 240),\n",
    "    patch_size=(5, 8, 8),\n",
    "    in_chans=5, num_classes=2,\n",
    "    debug=False,\n",
    ")\n",
    "summary(mambamodel, input_size=(1, 5, 155, 240, 240), depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e6c5126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "SwinTransformer3D                             [2, 2]                    --\n",
       "├─Conv3d: 1-1                                 [2, 96, 19, 30, 30]       245,856\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-1                        [2, 19, 30, 30, 96]       --\n",
       "│    │    └─SwinTransformerBlock3D: 3-1       [2, 19, 30, 30, 96]       112,608\n",
       "│    │    └─SwinTransformerBlock3D: 3-2       [2, 19, 30, 30, 96]       112,608\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Conv3d: 2-2                            [2, 192, 9, 15, 15]       147,648\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-3                        [2, 9, 15, 15, 192]       --\n",
       "│    │    └─SwinTransformerBlock3D: 3-3       [2, 9, 15, 15, 192]       446,400\n",
       "│    │    └─SwinTransformerBlock3D: 3-4       [2, 9, 15, 15, 192]       446,400\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Conv3d: 2-4                            [2, 384, 4, 7, 7]         590,208\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-5                        [2, 4, 7, 7, 384]         --\n",
       "│    │    └─SwinTransformerBlock3D: 3-5       [2, 4, 7, 7, 384]         1,777,536\n",
       "│    │    └─SwinTransformerBlock3D: 3-6       [2, 4, 7, 7, 384]         1,777,536\n",
       "│    │    └─SwinTransformerBlock3D: 3-7       [2, 4, 7, 7, 384]         1,777,536\n",
       "│    │    └─SwinTransformerBlock3D: 3-8       [2, 4, 7, 7, 384]         1,777,536\n",
       "│    │    └─SwinTransformerBlock3D: 3-9       [2, 4, 7, 7, 384]         1,777,536\n",
       "│    │    └─SwinTransformerBlock3D: 3-10      [2, 4, 7, 7, 384]         1,777,536\n",
       "├─ModuleList: 1-7                             --                        (recursive)\n",
       "│    └─Conv3d: 2-6                            [2, 768, 2, 3, 3]         2,360,064\n",
       "├─ModuleList: 1-8                             --                        (recursive)\n",
       "│    └─Sequential: 2-7                        [2, 2, 3, 3, 768]         --\n",
       "│    │    └─SwinTransformerBlock3D: 3-11      [2, 2, 3, 3, 768]         7,094,016\n",
       "│    │    └─SwinTransformerBlock3D: 3-12      [2, 2, 3, 3, 768]         7,094,016\n",
       "├─Conv3d: 1-9                                 [2, 768, 2, 3, 3]         590,592\n",
       "├─Sequential: 1-10                            [2, 2]                    --\n",
       "│    └─Linear: 2-8                            [2, 512]                  393,728\n",
       "│    └─ReLU: 2-9                              [2, 512]                  --\n",
       "│    └─Dropout: 2-10                          [2, 512]                  --\n",
       "│    └─Linear: 2-11                           [2, 2]                    1,026\n",
       "===============================================================================================\n",
       "Total params: 30,300,386\n",
       "Trainable params: 30,300,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 9.38\n",
       "===============================================================================================\n",
       "Input size (MB): 357.12\n",
       "Forward/backward pass size (MB): 833.19\n",
       "Params size (MB): 86.63\n",
       "Estimated Total Size (MB): 1276.93\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "xmerModel = SwinTransformer3D(img_size=(155, 240, 240), patch_size=(8,8,8), in_chans=5, num_classes=2)\n",
    "summary(xmerModel, input_size=(2, 5, *(155, 240, 240)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2eb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "VisionMamba3D                                      --\n",
       "├─Conv3d: 1-1                                      4,704\n",
       "├─ModuleList: 1-2                                  --\n",
       "│    └─Sequential: 2-1                             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-1           111,264\n",
       "│    │    └─TransformerBlockWithSSM: 3-2           111,264\n",
       "│    │    └─TransformerBlockWithSSM: 3-3           111,264\n",
       "│    │    └─TransformerBlockWithSSM: 3-4           111,264\n",
       "│    └─Sequential: 2-2                             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-5           443,712\n",
       "│    │    └─TransformerBlockWithSSM: 3-6           443,712\n",
       "│    │    └─TransformerBlockWithSSM: 3-7           443,712\n",
       "│    │    └─TransformerBlockWithSSM: 3-8           443,712\n",
       "│    └─Sequential: 2-3                             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-9           1,772,160\n",
       "│    │    └─TransformerBlockWithSSM: 3-10          1,772,160\n",
       "│    │    └─TransformerBlockWithSSM: 3-11          1,772,160\n",
       "│    │    └─TransformerBlockWithSSM: 3-12          1,772,160\n",
       "│    └─Sequential: 2-4                             --\n",
       "│    │    └─TransformerBlockWithSSM: 3-13          3,985,344\n",
       "│    │    └─TransformerBlockWithSSM: 3-14          3,985,344\n",
       "│    │    └─TransformerBlockWithSSM: 3-15          3,985,344\n",
       "│    │    └─TransformerBlockWithSSM: 3-16          3,985,344\n",
       "├─ModuleList: 1-3                                  --\n",
       "│    └─Conv3d: 2-5                                 147,648\n",
       "│    └─Conv3d: 2-6                                 590,208\n",
       "│    └─Conv3d: 2-7                                 1,770,048\n",
       "├─Conv3d: 1-4                                      332,352\n",
       "├─Sequential: 1-5                                  --\n",
       "│    └─LayerNorm: 2-8                              1,152\n",
       "│    └─Linear: 2-9                                 295,424\n",
       "│    └─ReLU: 2-10                                  --\n",
       "│    └─Linear: 2-11                                1,026\n",
       "===========================================================================\n",
       "Total params: 28,392,482\n",
       "Trainable params: 28,392,482\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "from model.VisionMamba3D import VisionMamba3D\n",
    "\n",
    "model = VisionMamba3D(\n",
    "    img_size=(155, 240, 240), patch_size=(4, 4, 3), in_chans=1, num_classes=2, depths=[4, 4, 4, 4],\n",
    "    ).to('cuda')\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "from mamba_ssm import Mamba\n",
    "from mamba_ssm import Mamba2\n",
    "from mamba_ssm.modules.mamba2_simple import Mamba2Simple\n",
    "\n",
    "# xs = [\n",
    "#     torch.randn(2, 16*1024, 96).to('cuda'),\n",
    "#     torch.randn(2, 16*1024//4, 192).to('cuda'),\n",
    "#     torch.randn(2, 16*1024//16, 384).to('cuda'),\n",
    "#     torch.randn(2, 16*1024//64, 576).to('cuda'),\n",
    "# ]\n",
    "xshapes = [(2, 16*1024, 96), (2, 16*1024//4, 192), (2, 16*1024//16, 384), (2, 16*1024//64, 576)]\n",
    "\n",
    "for xshape in xshapes:\n",
    "# for x in xs:\n",
    "    # batch, length, dim = x.shape\n",
    "    batch, length, dim = xshape\n",
    "    x = torch.randn(batch, length, dim).to('cuda')\n",
    "    for M in [Mamba, Mamba, Mamba, Mamba, Mamba, Mamba2, Mamba2, Mamba2, Mamba2, Mamba2, Mamba2Simple, Mamba2Simple, Mamba2Simple, Mamba2Simple, Mamba2Simple]:\n",
    "        try:\n",
    "            if (M==Mamba):\n",
    "                model = M(\n",
    "                    d_model=dim, # Model dimension d_model\n",
    "                    d_state=64,  # SSM state expansion factor, typically 64 or 128\n",
    "                    d_conv=4,    # Local convolution width\n",
    "                    expand=2,    # Block expansion factor\n",
    "                ).to(\"cuda\")\n",
    "            else:\n",
    "                model = M(\n",
    "                    d_model=dim, # Model dimension d_model\n",
    "                    d_state=64,  # SSM state expansion factor, typically 64 or 128\n",
    "                    headdim=4,  # Attention head dimension\n",
    "                    d_conv=4,    # Local convolution width\n",
    "                    expand=2,    # Block expansion factor\n",
    "                ).to(\"cuda\")\n",
    "            st = time.time()\n",
    "            if (model(x).shape!=xshape):\n",
    "                print(M.__name__, 'error')\n",
    "            print(M.__name__, time.time()-st)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66551eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(batch, length, dim)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m Mamba(\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# This module uses roughly 3 * expand * d_model^2 parameters\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     d_model\u001b[38;5;241m=\u001b[39mdim, \u001b[38;5;66;03m# Model dimension d_model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     expand\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,    \u001b[38;5;66;03m# Block expansion factor\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m y\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/vmamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vmamba/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vmamba/lib/python3.11/site-packages/mamba_ssm/modules/mamba2_simple.py:138\u001b[0m, in \u001b[0;36mMamba2Simple.forward\u001b[0;34m(self, u, seq_idx)\u001b[0m\n\u001b[1;32m    134\u001b[0m dt_limit_kwargs \u001b[38;5;241m=\u001b[39m {} \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_limit \u001b[38;5;241m==\u001b[39m (\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(dt_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdt_limit)\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_mem_eff_path:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# Fully fused path\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmamba_split_conv1d_scan_combined\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzxbcdt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43md 1 w -> d w\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseq_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrmsnorm_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrmsnorm_eps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutproj_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutproj_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaddim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaddim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mngroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_before_gate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitial_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdt_limit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     z, xBC, dt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(\n\u001b[1;32m    160\u001b[0m         zxbcdt, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_inner, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_inner \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/vmamba/lib/python3.11/site-packages/mamba_ssm/ops/triton/ssd_combined.py:908\u001b[0m, in \u001b[0;36mmamba_split_conv1d_scan_combined\u001b[0;34m(zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states, seq_idx, dt_limit, return_final_states, activation, rmsnorm_weight, rmsnorm_eps, outproj_weight, outproj_bias, headdim, ngroups, norm_before_gate)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmamba_split_conv1d_scan_combined\u001b[39m(zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, seq_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dt_limit\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)), return_final_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msilu\u001b[39m\u001b[38;5;124m\"\u001b[39m, rmsnorm_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, rmsnorm_eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, outproj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, outproj_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, headdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ngroups\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, norm_before_gate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    890\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;124;03m    Argument:\u001b[39;00m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;124;03m        zxbcdt: (batch, seqlen, 2 * dim + 2 * ngroups * dstate + nheads) where dim == nheads * headdim\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;124;03m        out: (batch, seqlen, dim)\u001b[39;00m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMambaSplitConv1dScanCombinedFn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzxbcdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_final_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrmsnorm_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrmsnorm_eps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutproj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutproj_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mngroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_before_gate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vmamba/lib/python3.11/site-packages/torch/autograd/function.py:574\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    573\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/vmamba/lib/python3.11/site-packages/torch/amp/autocast_mode.py:455\u001b[0m, in \u001b[0;36mcustom_fwd.<locals>.decorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cast_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fwd_used_autocast \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled(device_type)\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     autocast_context \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_enabled(device_type)\n",
      "File \u001b[0;32m~/miniconda3/envs/vmamba/lib/python3.11/site-packages/mamba_ssm/ops/triton/ssd_combined.py:757\u001b[0m, in \u001b[0;36mMambaSplitConv1dScanCombinedFn.forward\u001b[0;34m(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states, seq_idx, dt_limit, return_final_states, activation, rmsnorm_weight, rmsnorm_eps, outproj_weight, outproj_bias, headdim, ngroups, norm_before_gate)\u001b[0m\n\u001b[1;32m    754\u001b[0m zx0, z, xBC, dt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(zxbcdt, [\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m d_nonssm, dim, dim \u001b[38;5;241m+\u001b[39m ngroups \u001b[38;5;241m*\u001b[39m dstate \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, nheads], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    755\u001b[0m seq_idx \u001b[38;5;241m=\u001b[39m seq_idx\u001b[38;5;241m.\u001b[39mcontiguous() \u001b[38;5;28;01mif\u001b[39;00m seq_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    756\u001b[0m xBC_conv \u001b[38;5;241m=\u001b[39m rearrange(\n\u001b[0;32m--> 757\u001b[0m     \u001b[43mcausal_conv1d_cuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcausal_conv1d_fwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxBC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mb s d -> b d s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mconv1d_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv1d_bias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msilu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mswish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb d s -> b s d\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    760\u001b[0m )\n\u001b[1;32m    761\u001b[0m x, B, C \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msplit(xBC_conv, [dim, ngroups \u001b[38;5;241m*\u001b[39m dstate, ngroups \u001b[38;5;241m*\u001b[39m dstate], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    762\u001b[0m x \u001b[38;5;241m=\u001b[39m rearrange(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb l (h p) -> b l h p\u001b[39m\u001b[38;5;124m\"\u001b[39m, h\u001b[38;5;241m=\u001b[39mnheads)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from mamba_ssm import Mamba2\n",
    "from mamba_ssm.modules.mamba2_simple import Mamba2Simple as Mamba\n",
    "\n",
    "batch, length, dim = 10, 1024*1024, 128\n",
    "x = torch.randn(batch, length, dim).to(\"cuda\")\n",
    "model = Mamba(\n",
    "    # This module uses roughly 3 * expand * d_model^2 parameters\n",
    "    d_model=dim, # Model dimension d_model\n",
    "    d_state=64,  # SSM state expansion factor, typically 64 or 128\n",
    "    headdim=4,  # Attention head dimension\n",
    "    d_conv=4,    # Local convolution width\n",
    "    expand=2,    # Block expansion factor\n",
    ").to(\"cuda\")\n",
    "y = model(x)\n",
    "assert y.shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1368fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SimpleS4(nn.Module):\n",
    "    def __init__(self, d_model, seq_len):\n",
    "        super(SimpleS4, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.seq_len = seq_len\n",
    "        self.kernel = nn.Parameter(torch.randn(seq_len))\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, n, d = x.shape\n",
    "        # Convolution with the state-space kernel\n",
    "        x_fft = torch.fft.rfft(x, dim=1)\n",
    "        kernel_fft = torch.fft.rfft(self.kernel, n=n)\n",
    "        kernel_fft = kernel_fft.view(1, -1, 1) \n",
    "        out = torch.fft.irfft(x_fft * kernel_fft, n=n, dim=1)\n",
    "        return self.linear(out)\n",
    "\n",
    "# device = torch.device('cuda')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Usage\n",
    "seq_len = 102400\n",
    "d_model = 512\n",
    "x = torch.randn(1, seq_len, d_model).to(device)\n",
    "s4_model = SimpleS4(d_model, seq_len).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9609171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output = s4_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "012c1afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 102400, 512]), torch.Size([1, 102400, 512]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0b510d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.dataset' from 'c:\\\\Users\\\\shera\\\\Projects\\\\VisionMamba\\\\utils\\\\dataset.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from utils.dataset import TumorMRIDataset\n",
    "import utils\n",
    "reload(utils.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d55df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import TumorMRIDataset\n",
    "root_dir = './data/MICCAI_BraTS_2019_Data_Training/'\n",
    "# Dataset and DataLoader\n",
    "dataset = TumorMRIDataset(root_dir, limit=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a9340dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, *t2 = dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50a5fe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, [240, 240, 155])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a93c06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from model.modules.ssm import SSM\n",
    "\n",
    "ssm = SSM(\n",
    "    in_features=256,  # Dimension of the transformer model\n",
    "    dt_rank=32,  # Rank of the dynamic routing matrix\n",
    "    dim_inner=256,  # Inner dimension of the transformer model\n",
    "    d_state=256,  # Dimension of the state vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f67771c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'model.modules.ssm' from 'c:\\\\Users\\\\shera\\\\Projects\\\\VisionMamba\\\\model\\\\modules\\\\ssm.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "import model\n",
    "reload(model.modules.ssm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee41b2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
